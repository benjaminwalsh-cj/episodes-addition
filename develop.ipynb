{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.basicConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pipeline Test Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evaluation_scores(path: str, label: str) -> pd.DataFrame:\n",
    "    '''Load a precision_recall_fscore_file.xlsx from the path\n",
    "    Args:\n",
    "        path (`str`): path to evaluation scores file\n",
    "        label (`str`): label to distinguish the pipeline run\n",
    "    Returns:\n",
    "        Evaluation results dataframe formatted for further evaluation steps\n",
    "    Raises:\n",
    "        FileNotFoundError\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(path)\n",
    "    except FileNotFoundError:\n",
    "        logger.error('Path to evaluation file is incorrect.')\n",
    "        raise\n",
    "\n",
    "    df['label'] = label\n",
    "\n",
    "    return_df = df.melt(id_vars=['label', 'Category'], value_vars=['Precision', 'Recall', 'fscore'], value_name='values', var_name='measure')\n",
    "\n",
    "    return_df['values'] = return_df['values'].astype(float)\n",
    "\n",
    "    return return_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './all_egm/results/train/precision_recall_fscore/precision_recall_fscore_file.xlsx'\n",
    "\n",
    "post_df = load_evaluation_scores(path=path, label='all_egm')\n",
    "\n",
    "path = './no_egm/results/train/precision_recall_fscore/precision_recall_fscore_file.xlsx'\n",
    "\n",
    "pre_df = load_evaluation_scores(path=path, label='no_egm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_evaluation_scores(\n",
    "        pre_scores: pd.DataFrame,\n",
    "        post_scores: pd.DataFrame,\n",
    "        pre_label: str,\n",
    "        post_label: str) -> pd.DataFrame:\n",
    "    '''Create an evaluation dataframe to easily compare the evaluation results from\n",
    "    different pipeline runs\n",
    "    Args:\n",
    "        pre_scores (`pd.DataFrame`): testing evaluation results from base run\n",
    "        post_scores (`pd.DataFrame`): testing evaluation results from new run\n",
    "        pre_label (`str`): value of the `label` column in the pre dataframe\n",
    "        post_label (`str`): value of the `label` column in the post dataframe\n",
    "    Return:\n",
    "        Pandas dataframe for easier cross-runs comparisons of eval results\n",
    "    '''\n",
    "\n",
    "    if not isinstance(pre_scores, pd.DataFrame):\n",
    "        logger.error('Argument `pre_scores` is not a pandas dataframe.')\n",
    "        raise TypeError\n",
    "\n",
    "    if not isinstance(post_scores, pd.DataFrame):\n",
    "        logger.error('Argument `post_scores` is not a pandas dataframe.')\n",
    "        raise TypeError\n",
    "\n",
    "    # Merge on category and measure\n",
    "    merged_df = pre_scores.merge(post_scores, on=['Category', 'measure'])\n",
    "\n",
    "    # Drop label columns\n",
    "    merged_df = merged_df[['Category', 'measure', 'values_x', 'values_y']]\n",
    "\n",
    "    # Add delta\n",
    "    merged_df['delta'] = merged_df['values_y'] - merged_df['values_x']\n",
    "\n",
    "    # Flag if improved\n",
    "    merged_df['improve_flag'] = np.where(merged_df['delta'] > 0, 1, 0)\n",
    "\n",
    "    # Relabel columns\n",
    "    merged_df = merged_df.rename(\n",
    "        columns={\n",
    "            'values_x': f'{pre_label}_value',\n",
    "            'values_y': f'{post_label}_value'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>measure</th>\n",
       "      <th>no_egm_value</th>\n",
       "      <th>all_egm_value</th>\n",
       "      <th>delta</th>\n",
       "      <th>improve_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>Precision</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.998331</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cardiology</td>\n",
       "      <td>Precision</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>Recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cardiology</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.996283</td>\n",
       "      <td>0.998141</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other</td>\n",
       "      <td>fscore</td>\n",
       "      <td>0.998331</td>\n",
       "      <td>0.999165</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cardiology</td>\n",
       "      <td>fscore</td>\n",
       "      <td>0.998138</td>\n",
       "      <td>0.999070</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category    measure  no_egm_value  all_egm_value     delta  improve_flag\n",
       "0       Other  Precision      0.996667       0.998331  0.001664             1\n",
       "1  Cardiology  Precision      1.000000       1.000000  0.000000             0\n",
       "2       Other     Recall      1.000000       1.000000  0.000000             0\n",
       "3  Cardiology     Recall      0.996283       0.998141  0.001859             1\n",
       "4       Other     fscore      0.998331       0.999165  0.000834             1\n",
       "5  Cardiology     fscore      0.998138       0.999070  0.000932             1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_evaluation_scores(pre_scores=pre_df, post_scores=post_df, pre_label='no_egm', post_label='all_egm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Many in Each Class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions(path: str) -> pd.DataFrame:\n",
    "    '''Load a prediction file\n",
    "    Args:\n",
    "        path (`str`): path to the prediction file\n",
    "    Returns:\n",
    "        Dataframe of the predictions\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(path)\n",
    "    except FileNotFoundError:\n",
    "        logger.error('Could not find predictions at specified path.')\n",
    "        raise\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = './all_egm/results/propagate/prediction/prediction.xlsx'\n",
    "\n",
    "egm_preds = load_predictions(pred_path)\n",
    "\n",
    "pred_path = './no_egm/results/propagate/prediction/prediction.xlsx'\n",
    "\n",
    "no_preds = load_predictions(pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_class_counts(pred_df: pd.DataFrame, label: str) -> pd.DataFrame:\n",
    "    '''Count the number of predictions for each class in the passed df\n",
    "    Args:\n",
    "        pred_df (`pd.DataFrame`): prediction dataframe\n",
    "        label (`str`): label of the predictions' run\n",
    "    Returns:\n",
    "        Pandas dataframe of counts\n",
    "    '''\n",
    "    \n",
    "    # Generate counts\n",
    "    counts = pred_df['label_1'].value_counts()\n",
    "\n",
    "    # Store counts as a dataframe\n",
    "    counts_df = pd.DataFrame(counts)\n",
    "\n",
    "    # Add label\n",
    "    counts_df['label'] = label\n",
    "\n",
    "    # Extract category from index\n",
    "    counts_df['category'] = counts_df.index\n",
    "\n",
    "    # Relabel\n",
    "    counts_df = counts_df.rename(\n",
    "        columns={\n",
    "            'label_1': 'counts'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Reset index and reduce columns\n",
    "    counts_df = counts_df.reset_index()[\n",
    "        ['label', 'category', 'counts']\n",
    "    ]\n",
    "\n",
    "    return counts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_egm</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>28557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all_egm</td>\n",
       "      <td>Other</td>\n",
       "      <td>2785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label    category  counts\n",
       "0  all_egm  Cardiology   28557\n",
       "1  all_egm       Other    2785"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = gen_class_counts(pred_df, 'all_egm')\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_class_counts(\n",
    "        pre_counts: pd.DataFrame,\n",
    "        post_counts: pd.DataFrame,\n",
    "        pre_label: str,\n",
    "        post_label: str) -> pd.DataFrame:\n",
    "    '''Generate evaluation dataframe for class counts across runs\n",
    "    Args:\n",
    "        pre_counts (`pd.DataFrame`): class counts in initial pipeline run\n",
    "        post_counts (`pd.DataFrame`): class counts in changed pipeline run\n",
    "        pre_label (`str`): string label of initial run\n",
    "        post_label (`str`): string label of changed run\n",
    "    Returns:\n",
    "        Evaluation dataframe\n",
    "    '''\n",
    "\n",
    "    # Merge dfs\n",
    "    merge_df = pre_counts.merge(post_counts, on='category', how='inner')\n",
    "\n",
    "    # Add delta\n",
    "    merge_df['delta'] = merge_df['counts_y'] - merge_df['counts_x']\n",
    "\n",
    "    # Relabel\n",
    "    merge_df = merge_df.rename(\n",
    "        columns={\n",
    "            'counts_x': f'{pre_label}_count',\n",
    "            'counts_y': f'{post_label}_count'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Select columns\n",
    "    merge_df = merge_df[\n",
    "        [\n",
    "            'category',\n",
    "            f'{pre_label}_count',\n",
    "            f'{post_label}_count',\n",
    "            'delta'\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>no_egm_count</th>\n",
       "      <th>all_egm_count</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cardiology</td>\n",
       "      <td>28949</td>\n",
       "      <td>28557</td>\n",
       "      <td>-392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other</td>\n",
       "      <td>2393</td>\n",
       "      <td>2785</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category  no_egm_count  all_egm_count  delta\n",
       "0  Cardiology         28949          28557   -392\n",
       "1       Other          2393           2785    392"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df = gen_class_counts(no_preds, 'no_egm')\n",
    "post_df = gen_class_counts(egm_preds, 'all_egm')\n",
    "\n",
    "eval_class_counts(pre_df, post_df, 'no_egm', 'all_egm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73edeb63486cc3f58abf326bbf1fe353a792c5ed6d86f6fcdfde081eecf3f816"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
